{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import LinearConstraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization with two parameters in Gaussian distribution\n",
    "\n",
    "The objective of this notebook is to understand how to estimate parameters with gaussian distribution using the scipy.optimize package. \n",
    "\n",
    "Additionally, we define the search space to optimization methods similar to the parametric space of the distribution. This practice helps when the models have the parametric space more complex than the gaussian model described in this text.\n",
    "\n",
    "Hence, we assume the gaussian distributions, so the density is\n",
    "\\begin{equation}\n",
    "f_{Z}(z; \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\{-(z-\\mu)^2/2\\sigma^2\\}.\n",
    "\\tag{eq:01}\n",
    "\\end{equation}\n",
    "\n",
    "We illustrate the idea of finding parameters to the density applying  MLE (Maximum Likelihood Estimation). For this, we use log on both sides of the equation (eq:01),\n",
    "\\begin{equation}\n",
    "\\ell(z; \\mu, \\sigma)=\\log\\frac{1}{\\sigma} + \\log\\frac{1}{\\sqrt{2\\pi}} + \\log\\Bigg(\\exp\\{-(z-\\mu)^2/2\\sigma^2\\}\\Bigg),\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\ell(z; \\mu, \\sigma)=\\log\\sigma^{-1} + \\log\\sqrt{2\\pi}^{-1}-\\frac{1}{2\\sigma^2}(z-\\mu)^2,\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\ell(z; \\mu, \\sigma)=-\\log\\sigma - \\log\\sqrt{2\\pi}-\\frac{1}{2\\sigma^2}(z-\\mu)^2.\n",
    "\\tag{eq:02}\n",
    "\\end{equation}\n",
    "\n",
    "We used the equation (eq:02) intending to find the log-likelihood function\n",
    "\\begin{equation}\n",
    "\\mathcal{L}(\\mu, \\sigma)= \\sum_{i=1}^n\\ell(z_i; \\mu, \\sigma),\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\mathcal{L}(\\mu, \\sigma)= \\sum_{i=1}^n\\Bigg[-\\log\\big(\\sigma\\big) - \\log\\big(\\sqrt{2\\pi}\\big)-\\frac{1}{2\\sigma^2}(z_i-\\mu)^2\\Bigg],\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\mathcal{L}(\\mu, \\sigma)= -\\sum_{i=1}^n\\log\\big(\\sigma\\big) - \\sum_{i=1}^n\\log\\big(\\sqrt{2\\pi}\\big)-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n\\Bigg[\\frac{1}{2\\sigma^2}(z_i-\\mu)^2\\Bigg],\n",
    "\\end{equation}\n",
    "where, the algebraic manipulation results on the log-likelihood function with two parameters ($\\mu,\\sigma$),\n",
    "\\begin{equation}\n",
    "\\mathcal{L}(\\mu, \\sigma)= -n\\log\\big(\\sigma\\big) - n\\log\\big(\\sqrt{2\\pi}\\big)-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(z_i-\\mu)^2.\n",
    "\\tag{eq:03}\n",
    "\\end{equation}\n",
    " \n",
    "The code below defines the sample with mean and standard deviation, respectively equal to 1 and 2. Additionally, the code sets the log-likelihood function (eq:03)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglik(theta, x, N):\n",
    "    mu = theta[0]\n",
    "    sigma = theta[1]\n",
    "    # AAB: Signal because we use the minimize. \n",
    "    l = -(-N * np.log(np.sqrt(2*np.pi)) - N*np.log(sigma) - 0.5*np.sum((x - mu)**2/sigma**2))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean, SD\n",
      "0.9388169746796489 2.034329562565528\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "mean = 1\n",
    "sd = 2\n",
    "z = np.random.normal(mean, sd, n)\n",
    "np.mean(z)\n",
    "print(\"Mean, SD\")\n",
    "print(np.mean(z),np.std(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = 0.01\n",
    "ub = 10\n",
    "linear_constraint = LinearConstraint([[1, 0], [0, 1]], [lb, lb], [ub, ub])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply an optimization process using scipy.optimize package to find the parameters $\\mu$ and $\\sigma$. Some information are sumarized below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 212.910484\n",
      "         Iterations: 13\n",
      "         Function evaluations: 320\n",
      "         Gradient evaluations: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/optimize/_minimize.py:518: RuntimeWarning: Method BFGS cannot handle constraints nor bounds.\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "var = np.zeros(2)\n",
    "var[0] = 0.5\n",
    "var[1] = 0.5\n",
    "res = minimize(lambda varx:loglik(varx, z, n), var,\\\n",
    "                  method=\"BFGS\",\\\n",
    "                  constraints=linear_constraint,\\\n",
    "                  tol = 1e-08, \\\n",
    "                  options={'gtol': 1e-08, \\\n",
    "                           'eps': 1.4901161193847656e-08,\\\n",
    "                           'maxiter': 200, \\\n",
    "                           'disp': True,   \\\n",
    "                           'return_all': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  allvecs: [array([0.5, 0.5]), array([0.55422199, 1.50854349]), array([0.86359031, 1.49365219]), array([0.92562432, 1.58161968]), array([0.93548359, 1.79780905]), array([0.93807462, 1.92861107]), array([0.93897002, 2.00689349]), array([0.93900114, 2.03092263]), array([0.93890528, 2.03421583]), array([0.93885686, 2.0343297 ]), array([0.93883294, 2.03433293]), array([0.93881712, 2.03433004]), array([0.93881704, 2.03432964]), array([0.93881694, 2.03432954])]\n",
      "      fun: 212.9104844532822\n",
      " hess_inv: array([[0.05301502, 0.05196477],\n",
      "       [0.05196477, 0.10570153]])\n",
      "      jac: array([0.00000000e+00, 3.81469727e-06])\n",
      "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
      "     nfev: 320\n",
      "      nit: 13\n",
      "     njev: 77\n",
      "   status: 2\n",
      "  success: False\n",
      "        x: array([0.93881694, 2.03432954])\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
