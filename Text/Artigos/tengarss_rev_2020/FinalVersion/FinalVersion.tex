\documentclass[journal]{IEEEtran}

\usepackage{cite}
\usepackage{times}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage[boxed]{algorithm2e}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}             
\usepackage[utf8]{inputenc}                  
\usepackage{rotating}                       
\usepackage{mathtools}                       
\usepackage{bm,bbm}
\usepackage[binary-units]{siunitx}
\usepackage{url}
\usepackage[caption=false,font=footnotesize]{subfig}
\DeclareMathOperator{\traco}{tr}

\begin{document}
\title{Fusion of Evidences in Intensity Channels for Edge Detection in PolSAR Images}
\author{Anderson A.\ de Borba, Maurício Marengoni, and Alejandro C.\ Frery,~\IEEEmembership{Senior Member,~IEEE}%
\thanks{This study was financed in part by the Coordenação de Aperfeiçoamento de Pessoal de Nível Superior - Brasil (CAPES) - Finance Code 001}
\thanks{A.\ A.\ de Borba is with the Dept.\ Engenharia Elétrica e Computação, Universidade Presbiteriana Mackenzie (UPM), and with IBMEC-SP, São Paulo, Brazil. anderson.aborba@professores.ibmec.edu.br}
\thanks{M.\ Marengoni is with the Dept.\ Engenharia Elétrica e Computação,
UPM, São Paulo, Brazil. mauricio.marengoni@mackenzie.br}
\thanks{A.\ C.\ Frery is with the School of Mathematics and Statistics,
Victoria University of Wellington, 6140, New Zealand. alejandro.frery@vuw.ac.nz}}


\maketitle

\begin{abstract}
Polarimetric Synthetic Aperture Radar (PolSAR) sensors have reached an essential position in remote sensing. 
The images they provide have speckle noise, making their processing and analysis challenging tasks. 
We discuss an edge detection method based on the fusion of evidences obtained in the intensity channels hh, hv, and vv of PolSAR multi-look images. 
The method consists of detecting transition points in the thinnest possible range of data that covers two regions using maximum likelihood under the Wishart distribution. 
The fusion methods used are: 
simple average, 
multi-resolution discrete wavelet transform (MR-DWT),
principal component analysis (PCA), 
Receiver operating characteristic (ROC) statistics, 
multi-resolution stationary (MR-SWT) wavelet transform, 
and a multi-resolution method based on singular value decomposition (MR-SVD). 
A quantitative analysis suggests that PCA and MR-SVD provide the best results.
\end{abstract}

\begin{IEEEkeywords}
PolSAR, edge detection, maximum likelihood estimation, fusion methods. 
\end{IEEEkeywords}

\section{Introduction}\label{sec_01}
\IEEEPARstart{P}{olarimetric} synthetic aperture radar (PolSAR) has achieved an essential position in remote sensing. 
The data such sensors provide require specifically tailored signal processing techniques.
Among such techniques, edge detection is one of the most important operations for extracting information.
Edges are at a higher level of abstraction than mere data and, as such, provide relevant insights about the scene.

Among the available edge detection techniques for SAR and PolSAR images, it is worth mentioning: techniques based on denoising~\cite{sjx, lzly, wxbzw, cgaf};   
Markov random fields~\cite{bf};	
the deep learning approach~\cite{ztmxzxf} applied to segmentation and classification; and
statistical techniques~\cite{gmbf, fbgm, nhfc} applied in edge detection in PolSAR and SAR imagery.

This article follows the statistical modeling approach using the techniques described in~\cite{gmbf, fbgm, nhfc} to find edge evidences, followed by fusion processes~\cite{mit, bmf_2019}. 


Instead of handling fully polarimetric data, we treat each intensity channel separately, obtain evidence of edges, and then produce a single estimator of the edge position.
With this, we quantify the contribution each channel provides to the solution of the problem.

The Gambini Algorithm~\cite{gmbf_sc} is an attractive edge detection technique.
It is local, as it finds evidence of an edge over a thin strip of data; 
it works with any model, which makes it suitable for SAR data; 
and it has shown better performance than other approaches.
This algorithm consists in casting rays, and then finding the evidence of an edge in the ray by maximizing a value function.
We use the total likelihood of two samples: one inside the edge, another outside the edge.
Without loss of generality, we assume the complex scaled Wishart distribution for the fully polarimetric observations, from which Gamma laws stem for each intensity channel.
The value function depends on the estimates that index such Gamma laws; and
we estimate them by maximum likelihood.

The total likelihood function is non-differentiable at most points, and classical methods have difficulties in finding its maximum. 
We used the Generalized Simulated Annealing (GenSA)~\cite{xgsh} method to solve this problem. 

We discuss and compare six fusion methods:
Simple average~\cite{mit}, 
Multi-Resolution Discrete Wavelet, MR-DWT~\cite{n_r},
Principal Component Analysis, PCA~\cite{n_r,mit},
ROC statistics~\cite{gs},
Multi-Resolution Stationary Wavelet Transform, MR-SWT~\cite{n_r, jjly}, and 
Multi-Resolution Singular Value Decomposition, MR-SVD~\cite{naidu}.

The article is structured as follows.
Section~\ref{sec_02} describes the models.
Section~\ref{sec_03} describes the edge detection.
Section~\ref{sec_04} describes the approaches for fusing edge evidences.
Section~\ref{sec_05} presents the results.
In Section~\ref{sec_06} we discuss the results, and outline future research directions.

\section{Statistical modeling for PolSAR data}\label{sec_02}

Multi-looked fully polarimetric data follow the Wishart distribution with PDF defined by:
\begin{equation}
    f_{\mathbf{Z}}(\mathbf{z};\mathbf{\Sigma},L)=\frac{L^{pL}|\mathbf{z}|^{L-p}}{|\mathbf{\Sigma}|^{L}\Gamma_p(L)} \exp(-L\traco(\mathbf{\Sigma}^{-1}\mathbf{z})),
    \label{eq:DistWishart}
\end{equation} 
where $\mathbf z$ is a positive-definite Hermitian matrix, 
$L$ is the number of looks, 
$\traco(\cdot)$ is the trace operator of a matrix, $\Gamma_p(L)$ is the multivariate Gamma function defined by $
	\Gamma_p(L)=\pi^{\frac{1}{2}p(p-1)} \prod_{i=0}^{p-1}\Gamma(L-i)$,
and $\Gamma(\cdot)$ is the Gamma function.
We used three $p=3$ channels in this study. 
This situation is denoted by $\mathbf{Z}\sim W(\mathbf{\Sigma}, L)$, which satisfies $E[\mathbf{Z}]=\mathbf{\Sigma}$. 
This assumption usually holds for fully developed speckle but, since we will estimate $L$ locally instead of considering the same number of looks for the whole image, we will in part take into account departures from such hypothesis.

Since we are interested in describing the information conveyed by parts of such matrix under the Wishart model, we assume that the distribution of each intensity channel is a 
Gamma law with probability density function
\begin{equation}
f_Z(z;\mu,L)=\frac{L^{L}z^{L-1}}{\mu^{L}\Gamma(L)} \exp\big\{-Lz/\mu\big\},\quad z>0,
\label{func_dens_uni_gamma}
\end{equation}
where $L>0$, and
$\mu>0$ is the mean.
The log-likelihood of the sample $\bm z = (z_1,\dots,z_n)$ under this model is
\begin{equation}
\mathcal L(\mu, L; \bm z) = 
n \big[L\ln (L / \mu) - \ln \Gamma(L)\big]
+L \sum_{k=1}^{n}\ln z_k -\frac{L}{\mu}\sum_{k=1}^{n} z_k.
\label{eq:LogLikelihoodGamma}
\end{equation}

We obtain $\big(\widehat \mu, \widehat L\big)$, the maximum likelihood estimator (MLE) of $(\mu, L)$ based on $\bm z$, by maximizing~\eqref{eq:LogLikelihoodGamma} with the BFGS (Broyden-Fletcher-Goldfarb-Shanno) method~\cite{ht}.
We prefer optimization to solving $\nabla\mathcal L=\bm 0$ for improved numerical stability.

\section{Edge Detection on a Single Data Strip}\label{sec_03}

The Gambini algorithm estimates the point at which the properties of a sample change.
It has been used with stochastic distances~\cite{nhfc}, and with the likelihood function~\cite{gmbf, fbgm} for edge detection in SAR/PolSAR imagery.
It can be adapted to any suitable measure of dissimilarity between two samples.

The algorithm starts by casting rays from a point inside the candidate region, e.g., the centroid.
Data are collected around each ray to form the sample $\bm z = (z_1,z_2,\dots,z_n)$, which is partitioned at position $j$:
$$
\bm z = (\underbrace{z_1,z_2,\dots,z_j}_{\bm z_\text{I}}, 
\underbrace{z_{j+1}, z_{j+2},\dots,z_n}_{\bm z_\text{E}}).
$$
We assume two (possibly) different models for each partition:
$\bm Z_\text{I} \sim \Gamma(\mu_\text{I},L_\text{I})$, and 
$\bm Z_\text{E} \sim \Gamma(\mu_\text{E},L_\text{E})$.
We then estimate $(\mu_\text{I},L_\text{I})$ and $(\mu_\text{E},L_\text{E})$ with $\bm z_\text{I}$ and $\bm z_\text{E}$, respectively, by maximizing~\eqref{eq:LogLikelihoodGamma}, and obtain $\big(\widehat{\mu}_\text{I}, \widehat{L}_\text{I}\big)$ and $\big(\widehat{\mu}_\text{E}, \widehat{L}_\text{E}\big)$.

We then compute the total log-likelihood of $\bm z_\text{I}$ and $\bm z_\text{E}$:
\begin{equation}\label{eq:TotalLogLikelihood}
\begin{aligned}
\mathcal L\big(j&;\widehat{\mu}_I, \widehat{L}_I,\widehat{\mu}_E, \widehat{L}_E\big)= -\Bigg(
	\frac{\widehat{L}_\text{I}}{\widehat{\mu}_\text{I}}\sum_{k=1}^{j} z_k +
	\frac{\widehat{L}_\text{E}}{\widehat{\mu}_\text{E}}\sum_{k=j+1}^{n} z_k  
	\Bigg)+\mbox{}\\
&j \big[\widehat{L}_\text{I}\ln (\widehat{L}_\text{I} / \widehat{\mu}_\text{I}) - \ln \Gamma(\widehat{L}_\text{I})\big]
+\widehat{L}_\text{I} \sum_{k=1}^{j}\ln z_k + \mbox{}\\
&(n-j) \big[\widehat{L}_\text{E}\ln (\widehat{L}_\text{E} / \widehat{\mu}_\text{E}) - \ln \Gamma(\widehat{L}_\text{E})\big]
+\widehat{L}_\text{E} \sum_{k=j+1}^{n}\ln z_k .%-\\ 
\raisetag{2.2em}
\end{aligned}
\end{equation}
and the estimate of the edge position on the ray is the coordinate $\widehat\jmath$ which maximizes it.

Algorithm~\ref{Algo:GambiniEdgeDetection} is the pseudocode of the basic edge detection with the Gambini Algorithm.
We found that one hundred rays is a good compromise between spatial continuity and computational load.
Also, $\min_s$ is the minimum sample size.

\begin{algorithm}[hbt]
\SetAlgoLined
\KwData{$n_c$ intensity channels, interior point, number of rays}
\KwResult{$n_c$ binary images with evidences of edges}
%initialization\;
\For{each band $1\leq c\leq n_c$}{
	\For{each ray passing through the interior point}{
		$\bm z = (z_1,z_2,\dots,z_n)\leftarrow$ data collected around the ray\;
		\For{each $\min_s\leq j\leq n-\min_s$}{\nllabel{Line:InitFor}
			Partition the sample as $\bm z_{\text{I}}=(z_{\min_s},\dots,z_j)$ and 
			$\bm z_{\text{E}}=(z_{j+1},\dots,z_{n-\min_s})$\;
			Compute $\big(\widehat{\mu}_\text{I}, \widehat{L}_\text{I}\big)$ with $\bm z_{\text{I}}$, and $\big(\widehat{\mu}_\text{E}, \widehat{L}_\text{E}\big)$ with $\bm z_{\text{E}}$\;
			Compute the total log-likelihood at $j$ as $\mathcal L\big(j;\widehat{\mu}_I, \widehat{L}_I,\widehat{\mu}_E, \widehat{L}_E\big)$\;
		}
		$\widehat\jmath\leftarrow$ the value of $j$ which maximizes the total log-likelihood function\;
		\Return $(\widehat x, \widehat y)$, the coordinates of each $\widehat\jmath$\;
	}
\Return the binary image $\widehat{\bm\jmath}_c$ with $1$ at every $(\widehat x, \widehat y)$, and $0$ otherwise.
}
\caption{Gambini algorithm for intensity channels}\label{Algo:GambiniEdgeDetection}
\end{algorithm}

In our implementation, we replace the exhaustive sequential search (the innermost \textbf{for} loop) by Generalized Simulated Annealing (GenSA~\cite{xgsh}).


\section{Fusion of Evidences}\label{sec_04}

Assume we have $n_c$ binary images $\{\widehat{\bm\jmath}_c\}_{1\leq c\leq n_c}$ in which~$1$ denotes an estimate of edge and $0$ otherwise.
They have common size $m\times n$; denote $\ell=mn$.
These images will be fused to obtain the binary image $\bm I_F$.

We compare the results of six fusion techniques:
simple average, 
multi-resolution discrete wavelet transform (MR-DWT),
principal components analysis (PCA), 
ROC statistics,
multi-resolution stationary wavelet transform (MR-SWT), and
multi-resolution singular value decomposition (MR-SVD).

\subsection{Simple Average}
The simple average fusion method proposes the arithmetic mean of the edge evidence in each of the $n_c$ channels:
$\bm I_F(x,y)=(n_c)^{-1}\sum_{c=1}^{n_c} \widehat{\bm\jmath}_c(x,y)$,
where $1\leq x\leq m$ indexes the rows, and $1\leq y\leq n$ the columns of the image.

\subsection{Multi-Resolution Discrete Wavelet -- MR-DWT} 
This section is based on~\cite{n_r}.
We apply DWT filters on each binary image $\bm{\widehat\jmath}_c$: a low-pass filter $\bm L$ in the vertical direction, and a high-pass filter $\bm H$ in the horizontal direction, then both are down-sampled to create the coefficient matrices $\bm{\widehat\jmath}_{c\text{L}}$ and $\bm{\widehat\jmath}_{c\text{H}}$.
These operations are repeated on the coefficient matrices, leading to $\bm{\widehat\jmath}_{c\text{LL}}$, $\bm{\widehat\jmath}_{c\text{LH}}$, $\bm{\widehat\jmath}_{c\text{HL}}$, and $\bm{\widehat\jmath}_{c\text{HH}}$.
We, thus, use two resolution levels.

The DWT fusion method has the following steps:
\begin{enumerate}
\item Calculate the DWT decomposition $\bm{\widehat\jmath}_{c\text{LL}}$, $\bm{\widehat\jmath}_{c\text{LH}}$, $\bm{\widehat\jmath}_{c\text{HL}}$, and $\bm{\widehat\jmath}_{c\text{HH}}$, for each channel.
\item Compute $\bm{\bar\jmath}_{c\text{HH}}$, the pixel-wise mean of all $\bm{\widehat\jmath}_{c\text{HH}}$ decompositions.
\item Find the pixel-wise maximum of $\bm{\widehat\jmath}_{c\text{LL}}$, $\bm{\widehat\jmath}_{c\text{LH}}$, $\bm{\widehat\jmath}_{c\text{HL}}$: $\bm{\bar\jmath}_{c\text{LL}}$, $\bm{\bar\jmath}_{c\text{LH}}$, and $\bm{\bar\jmath}_{c\text{HL}}$.
\item The result of the fusion $I_F$ is the inverse DWT transform of the coefficient matrices $\bm{\bar\jmath}_{c\text{HH}}$, $\bm{\bar\jmath}_{c\text{LL}}$, $\bm{\bar\jmath}_{c\text{LH}}$, and $\bm{\bar\jmath}_{c\text{HL}}$.
\end{enumerate}

\subsection{Principal Component Analysis -- PCA}

This section is based on~\cite{n_r,mit}.
The method is comprised of the following steps:
\begin{enumerate}
\item Stack the binary images $\bm{\widehat\jmath}_c$ in column vectors to obtain the matrix $\bm X_{\ell\times n_c}$.
\item Calculate the covariance matrix $\bm C_{n_c\times n_c}$ of $\bm X_{\ell\times n_c}$.
\item Compute the matrices of eigenvalues ($\bm\Lambda$) and eigenvectors ($\bm V$) of the covariance matrix, sorted in decreasing order by the eigenvalues. 
\item Compute the vector $\bm P=(P(1),\dots,P(n_c))=(\sum_{c=1}^{n_c} V(c))^{-1}{\bm V}$, where $\bm V$ is eigenvector associated with the highest eigenvalue of $\bm C_{n_c\times n_c}$; notice that $\sum_{c=1}^{n_c} P(c)=1$.
\item Fuse $\bm I_F(x,y)=\sum_{c=1}^{n_c} P(c)\bm{\widehat\jmath}_c(x,y)$.
\end{enumerate}

\subsection{ROC Statistics}
The ROC method was proposed and described on~\cite{gs}:
\begin{enumerate}  
\item Add the binary images $\bm{\widehat\jmath}_c$ to produce the frequency matrix ($\bm V$).
\item Use thresholds ranging from $t=1,\dots,n_c$ on $\bm V$ to generate matrices $\bm M_t$.
\item Compare each $\bm M_t$ with all $\bm{\widehat\jmath}_c$, find the confusion matrix to generate the ROC curve. 
The optimal threshold corresponds to the point of the ROC curve closest (in the sense of the Euclidean distance) to the diagnostic line.
\item The fusion $\bm I_F$ is the matrix $\bm M_t$ which corresponds to the optimal threshold.
\end{enumerate}

\subsection{Multi-Resolution Stationary Wavelet Transform -- MR-SWT}  
This section is based on~\cite{n_r, jjly}. The difference between MR-DWT and MR-SWT method is the replacement of the 
Discrete Wavelet Transform (DWT) by the
Stationary Wavelet Transform SWT. 

\subsection{Multi-Resolution Singular Value Decomposition -- MR-SVD}

MR-SVD Fusion~\cite{naidu} works similarly to MR-DWT. 
The MR-SVD fusion method can be summarized as follows:
\begin{enumerate}
\item Organize the binary image $\bm{\widehat\jmath}_c$ as non-overlapping $2\times 2$ blocks, and arrange each block as a $4\times 1$ vector by stacking columns to form the data matrix $\bm X_1$ with dimension ${4\times{\ell}/{4}}$.
\item Find the SVD decomposition of $\bm X_1=\bm U_1 \bm S_1 \bm V_1^T$, where $\bm U_1$ is a ${4\times 4}$ unitary matrix, $\bm S_1$ is a $4\times{\ell}/{4}$ rectangular diagonal matrix known as singular values matrix, and $\bm V_1$ is an ${\ell}/{4}\times{\ell}/{4}$~unitary matrix. The singular values are ordered in a decreasing order.
\item 
Transform the lines of $\widehat{\bm X}_1=\bm U_1^T\bm X_1=\bm S_1 \bm V_1^T$ into new matrices with dimensions ${m}/{2}\times{n}/{2}$: $\{\bm\Phi_1, \bm\Psi_{1\text{V}}, \bm\Psi_{1\text{H}}, \bm\Psi_{1\text{D}}\}$.  
\item Repeat the procedure (1) on $\bm\Phi_r$ by $r=2$ up to the lowest resolution level $R$. 
\item The MR-SVD decomposition in each channel is
\begin{equation}\nonumber
\widehat{\bm X}_c\rightarrow \left\{\bm \Phi_\text{R}^c,\{\bm\Psi_{r\text{V}}^c,\bm\Psi_{r\text{H}}^c,\bm\Psi_{r\text{D}}^c \}_{r=1}^\text{R},\{\bm U_r^c	\}_{r=1}^\text{R} \right\}.
\end{equation}
\item Once the decomposition is applied to all channels, 
compute the average of $\bm\Phi_R^c$ ($\bm\Phi_\text{R}^f$) in the lowest resolution level, and the average 
of $\bm U_r^c$ ($\bm U_\text{r}^f$), for each $r$, where $f$ denotes the fusion among channels. 
\item Find the pixel-wise maxima of $\bm\Psi_{r\text{V}}^c$, $\bm\Psi_{r\text{H}}^c$ and $\bm\Psi_{r\text{D}}^c$: $ \bm\Psi_{rV}^f$ $\bm\Psi_{r\text{V}}^f$, $\bm\Psi_{r\text{H}}^f$ and $\bm\Psi_{r\text{D}}^f$.
\item The fusion $\bm I_F$ is the SVD transformation for each level $r=\text{R},\dots,1$,  
\begin{equation}\nonumber
\bm I_F\leftarrow \left\{\bm \Phi_\text{R}^f,\{\bm\Psi_{r\text{V}}^f,\bm\Psi_{r\text{H}}^f,\bm\Psi_{r\text{D}}^f \}_{r=\text{R}}^1,\{\bm U_r^f\}_{r=\text{R}}^1 \right\}.
\end{equation}
\end{enumerate}
We also used two resolution levels.

\section{Results}\label{sec_05}

\subsection{Flevoland images}

Fig.~\ref{roi_gt}\subref{flevoland_radial_4look} shows a $750\times 1024$ pixels AIRSAR (Airborne Synthetic Aperture Radar) PolSAR image of Flevoland, L-band, with the radial lines where edges are detected. 
Fig.~\ref{roi_gt}\subref{gt_flevoland} shows the ground reference in red.  

\begin{figure}[hbt]
   \centering
     \subfloat[Image and rays. \label{flevoland_radial_4look}]{%  
       \includegraphics[width=0.229\textwidth]{flevoland_radial_4_look_black_crop}}
     \subfloat[Ground reference\label{gt_flevoland}]{%
       \includegraphics[width=0.216\textwidth]{gt_flevoland_crop}
     }
    \caption{Flevoland image in Pauli decomposition, and ground reference}
    \label{roi_gt}
\end{figure}

Figs.~\ref{evidencias_hh_hv_vv}\subref{evidencias_hh_hv_vv:a}, \ref{evidencias_hh_hv_vv}\subref{evidencias_hh_hv_vv:b}, and~\ref{evidencias_hh_hv_vv}\subref{evidencias_hh_hv_vv:c} show, respectively, the edge evidences in the $\text{hh}$, $\text{hv}$ and $\text{vv}$ channels as obtained by MLE.

It is worth noting that GenSA has accurately identified the maximum value of $\mathcal L$ (Eq.~\eqref{eq:TotalLogLikelihood}), even in the presence of multiple local maxima. 
A visual assessment leads to conclude that the best results are provided by $\text{hv}$, although with a few points far from the actual edge.

   \begin{figure}[hbt]
	\centering
     \subfloat[Channel $\text{hh}$ \label{evidencias_hh_hv_vv:a}]{%
       \includegraphics[width=0.32\linewidth]{flevoland_hh_evid_param_L_mu_14_pixel_crop}
     }
     \subfloat[Channel $\text{hv}$ \label{evidencias_hh_hv_vv:b}]{%
       \includegraphics[width=0.32\linewidth]{flevoland_hv_evid_param_L_mu_14_pixel_crop}
     }
     \subfloat[Channel $\text{vv}$ \label{evidencias_hh_hv_vv:c}]{%
       \includegraphics[width=0.32\linewidth]{flevoland_vv_evid_param_L_mu_14_pixel_crop}
     }
     \caption{Edges evidences from the three intensity channels}
     \label{evidencias_hh_hv_vv} 
   \end{figure}

Figs.~\ref{fusion_met}\subref{fusion_met:a}, 
\ref{fusion_met}\subref{fusion_met:b}, 
\ref{fusion_met}\subref{fusion_met:c}, 
\ref{fusion_met}\subref{fusion_met:d}, 
\ref{fusion_met}\subref{fusion_met:e}, 
and~\ref{fusion_met}\subref{fusion_met:f} show the results of fusing these evidences. 
  
Simple average and PCA produce similar results.
MR-SVD produces considerably less outliers than the other methods.
ROC produces accurate edges, with few outliers, but sparsely. 
Both wavelet-based methods (DWT and SWT) produce too dense edges and many outliers.

\begin{figure}[hbt]
	\centering
     \subfloat[Average fusion\label{fusion_met:a}]{%
       \includegraphics[width=0.32\linewidth]{flevoland_fus_media_param_L_mu_14_pixel_crop}
     }
     \subfloat[MR-DWT fusion\label{fusion_met:b}]{%
       \includegraphics[width=0.32\linewidth]{flevoland_fus_dwt_param_L_mu_14_pixel_crop}
     }
     \subfloat[PCA fusion \label{fusion_met:c}]{%
       \includegraphics[width=0.32\linewidth]{flevoland_fus_pca_param_L_mu_14_pixel_crop}       
     }\\
     \subfloat[ROC fusion\label{fusion_met:d}]{%
       \includegraphics[width=0.32\linewidth]{flevoland_fus_roc_param_L_mu_14_pixel_crop}
     }
     \subfloat[MR-SWT fusion\label{fusion_met:e}]{%
       \includegraphics[width=0.32\linewidth]{flevoland_fus_swt_param_L_mu_14_pixel_crop}
     }
     \subfloat[MR-SVD fusion\label{fusion_met:f}]{%
       \includegraphics[width=0.32\linewidth]{flevoland_fus_svd_param_L_mu_14_pixel_crop}
     }
     \caption{Results of applying the six fusion methods}
     \label{fusion_met}
\end{figure}

Fig.~\ref{roi_gt_2} shows another region in the Flevoland image.
In this case, it is a bright target surrounded by darker fields.
Fig.~\ref{evidencias_flev_hh_hv_vv} shows the edges detected in each intensity channel and, again, the hv data are the one which produce the most accurate results.

\begin{figure}[hbt]
	\centering
	\subfloat[Image and rays. \label{flevoland_radial_25}]{%  
		\includegraphics[width=.48\linewidth]{flevoland_r3_radial_crop}}
	\subfloat[Ground reference\label{gt_flevoland_r3_crop}]{%
		\includegraphics[width=.48\linewidth]{gt_flevoland_r3_crop}
	}
	\caption{Flevoland image in Pauli decomposition, and ground reference}
	\label{roi_gt_2}
\end{figure}

\begin{figure}[hbt]
	\centering
	\subfloat[Channel $\text{hh}$ \label{evidencias_flev_hh_hv_vv:a}]{%
		\includegraphics[width=0.32\linewidth]{evid_real_flev_hh_param_L_mu_25_pixel_r3_crop}
	}
	\subfloat[Channel $\text{hv}$ \label{evidencias_flev_hh_hv_vv:b}]{%
		\includegraphics[width=0.32\linewidth]{evid_real_flev_hv_param_L_mu_25_pixel_r3_crop}
	}
	\subfloat[Channel $\text{vv}$ \label{evidencias_flev_hh_hv_vv:c}]{%
		\includegraphics[width=0.32\linewidth]{evid_real_flev_vv_param_L_mu_25_pixel_r3_crop}
	}
	\caption{Edges evidences from the three intensity channels, Flevoland image}
	\label{evidencias_flev_hh_hv_vv} 
\end{figure}

Fig.~\ref{fusion_flev_met} shows the two best fusion results: PCA and MR-SVD.
Notice that the latter (Fig.~\ref{fusion_flev_met}\subref{fusion_flev_met:f}) eliminates the wrong detection close to the center of the area, and has fewer wrongly detected points outside the region of interest.

\begin{figure}[hbt]
	\centering
	\subfloat[PCA fusion \label{fusion_flev_met:c}]{%
		\includegraphics[width=0.48\linewidth]{flev_r3_fus_pca_param_L_mu_25_pixel_crop}       
	}
	\subfloat[MR-SVD fusion\label{fusion_flev_met:f}]{%
		\includegraphics[width=0.48\linewidth]{flev_r3_fus_svd_param_L_mu_25_pixel_crop}
	}
	\caption{Two best fusion results in the Flevoland image}
	\label{fusion_flev_met}
\end{figure}

\subsection{San Francisco Image}

Fig.~\ref{roi_gt_SF} shows an area of an L-band AIRSAR image over San Francisco.
The distinctive areas are urban, sea, and vegetation.
The aim is finding the edge between the former and the other two.

\begin{figure}[hbt]
	\centering
	\subfloat[Image and rays. \label{san_francisco_radial_25}]{%  
		\includegraphics[width=0.48\linewidth]{san_francisco_radial_25_crop}}\  
	\subfloat[Ground reference\label{gt_san_francisco}]{%
		\includegraphics[width=0.48\linewidth]{gt_san_fran_r1_crop}
	}
	\caption{San Francisco image in Pauli decomposition, and ground reference}
	\label{roi_gt_SF}
\end{figure}

Fig.~\ref{evidencias_sf_hh_hv_vv} shows the evidences of edges found in each of the three intensity channels.
A visual inspection suggests that the hh channel is the one that produces the best estimation.

\begin{figure}[hbt]
	\centering
	\subfloat[Channel $\text{hh}$ \label{evidencias_sf_hh_hv_vv:a}]{%
		\includegraphics[width=0.32\linewidth]{evid_real_sf_1_param_L_mu_25_pixel_r1_crop}
	}
	\subfloat[Channel $\text{hv}$ \label{evidencias_sf_hh_hv_vv:b}]{%
		\includegraphics[width=0.32\linewidth]{evid_real_sf_2_param_L_mu_25_pixel_r1_crop}
	}
	\subfloat[Channel $\text{vv}$ \label{evidencias_sf_hh_hv_vv:c}]{%
		\includegraphics[width=0.333\linewidth]{evid_real_sf_3_param_L_mu_25_pixel_r1_crop}
	}
	\caption{Edges evidences from the three intensity channels to San Francisco}
	\label{evidencias_sf_hh_hv_vv} 
\end{figure}

Fig.~\ref{fusion_sf_met} shows the two best fusion results: PCA and MR-SVD.
Again, the latter is more resistant to outliers, both inside and outside the region of interest.

\begin{figure}[hbt]
	\centering
	\subfloat[PCA fusion \label{fusion_sf_met:c}]{%
		\includegraphics[width=0.48\linewidth]{sf_fus_pca_param_L_mu_25_pixel_crop}       
	}
	\subfloat[MR-SVD fusion\label{fusion_sf_met:f}]{%
		\includegraphics[width=0.48\linewidth]{sf_fus_svd_param_L_mu_25_pixel_crop}
	}
	\caption{Two best fusion results in the San Francisco image}
	\label{fusion_sf_met}
\end{figure}

\subsection{Error analysis}

Figure~\ref{probability_edge_detc} shows the error of $\widehat\jmath$ in finding the true edge shown in Fig.~\ref{roi_gt}\subref{gt_flevoland}, as measured on $100$ lines with
the minimum Euclidean distance between the ground truth and the detected pixel in the fusion methods.
We use relative frequencies to estimate the probability of having an error smaller than a number of pixels. 
Denoting $H(k)$ the number of lines for which the error is less than $k$ pixels, 
an estimate of this probability is $f(k)={H(k)}/{n_r}$, where $n_r$ is number of lines. 
In our analysis, $k$ varies between $1$ and $10$, and $n_r=100$. 
The algorithm is described in Ref.~\cite{fbgm}.

\begin{figure}[hbt]
	\centering
	\includegraphics[width=.7\linewidth]{metricas_6_fusao_flevoland}
	\caption{Probability of detecting the edge by the fusion methods in Fig.~\ref{roi_gt}.}
	\label{probability_edge_detc}
\end{figure}

We obtained similar results on the images shown in Figs.~\ref{roi_gt_2} and~\ref{roi_gt_SF}, which we omit for brevity.

\subsection{Implementation Details}\label{Sec:Implementation}

Table~\ref{metrica_de_tempo} shows the running times (absolute and relative to the fastest method).
The system presented here was executed on a Intel\copyright\ Core i7-9750HQ CPU \SI{2.6}{\giga\hertz} \SI{16}{\giga\byte} RAM computer. 

\begin{table}[hbt]
	\centering
	\caption{Processing times (fusion method).}\label{metrica_de_tempo}
	\begin{tabular}{@{}lrrrrrr@{}} \toprule
		Method       & Aver.   &   PCA      &  MR-DWT  & MR-SWT &  ROC  &  MR-SVD \\ \midrule
		Time (s)      & 0.01      & 0.02       &  0.08 & 0.18      &  0.40       & 1.11  \\
		Rel. time     & 1.00      & 2.19       &  9.25 & 21.05     &  46.59      & 129.57  \\ \bottomrule
	\end{tabular}
\end{table}

The method for detecting edge evidence MLE was implemented in the R language.
The fusion methods were implemented in Matlab. 
Code and data are available at \url{https://github.com/anderborba/Code_GRSL_2020_1}.


\section{Conclusion}\label{sec_06}

We found evidence of edges using the maximum likelihood method under the Wishart model for PolSAR data. 
The evidence was found in each of the three intensity channels of AIRSAR L-band images over Flevoland and San Francisco.

Over the agricultural fields of Flevoland, the best edge evidence was observed on the hv channel. 
The hh channel provided the best estimates of the edges between the urban and both sea and vegetation areas of San Francisco.
Such diversity of information content justifies the need of fusing the edge evidences.

We applied simple average, MR-DWT, PCA, ROC, MR-SWT, and MR-SVD fusion methods to aggregate the evidence obtained in the three channels.
The best results were produced by PCA and by the Multi-Resolution Singular Value Decomposition (MR-SVD).
Such enhancement comes at additional computational cost in terms of processing time.

We quantitatively assessed the results by checking the closeness of the fused points to the actual edge, and by the presence of outliers.
Although the average and PCA are similar with respect to the probability of correctly detecting the edge, the latter provides a more effective weight of the evidences.
In fact, PCA is able to completely discard misleading evidences, while the average cannot.

Two avenues for future improvement of the fusion are:
(1)~increasing the number of evidences.
	This is possible, since fully polarimetric data are richer than mere intensity channels; and
(2)~post-processing of both partial evidences and fusion.

%\bibliographystyle{IEEEtran}
%\bibliography{../RefsTengars2020}
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
%\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
%\providecommand{\BIBentryALTinterwordstretchfactor}{4}
%\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
%\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
%  \fontdimen4\font\relax}
%\providecommand{\BIBforeignlanguage}[2]{{%
%\expandafter\ifx\csname l@#1\endcsname\relax
%\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
%\typeout{** loaded for the language `#1'. Using the pattern for}%
%\typeout{** the default language instead.}%
%\else
%\language=\csname l@#1\endcsname
%\fi
%#2}}
%\providecommand{\BIBdecl}{\relax}
%\BIBdecl
\bibitem{sjx}
J.~{Shi}, H.~{Jin}, and Z.~{Xiao}, ``A novel hybrid edge detection method for
  polarimetric {SAR} images,'' \emph{IEEE Access}, vol.~8, pp. 8974--8991,
  2020.

\bibitem{lzly}
B.~{Liu}, Z.~{Zhang}, X.~{Liu}, and W.~{Yu}, ``Edge extraction for polarimetric
  {SAR} images using degenerate filter with weighted maximum likelihood
  estimation,'' \emph{IEEE Geosci. Remote Sens. Lett.}, vol.~11, no.~12, pp.
  2140--2144, Dec 2014.

\bibitem{wxbzw}
W.~Wang, D.~Xiang, Y.~Ban, J.~Zhang, and J.~Wan, ``Enhanced edge detection for
  polarimetric {SAR} images using a directional span-driven adaptive window,''
  \emph{Int. J. Remote Sens.}, vol.~39, no.~19, pp. 6340--6357, 2018.

\bibitem{cgaf}
D.~{Santana-Cedrés}, L.~{Gomez}, L.~{Alvarez}, and A.~C. {Frery},
  ``Despeckling {PolSAR} images with a structure tensor filter,'' \emph{IEEE
  Geosci. Remote Sens. Lett.}, vol.~17, no.~2, pp. 357--361, Feb 2020.

\bibitem{bf}
F.~Baselice and G.~Ferraioli, ``Statistical edge detection in urban areas
  exploiting {SAR} complex data,'' \emph{IEEE Geosci. Remote Sens. Lett.},
  vol.~9, no.~2, pp. 185--189, March 2012.

\bibitem{ztmxzxf}
X.~X. Zhu, D.~Tuia, L.~Mou, G.~Xia, L.~Zhang, F.~Xu, and F.~Fraundorfer, ``Deep
  learning in remote sensing: A comprehensive review and list of resources,''
  \emph{IEEE Geosci. Remote Sens. Mag.}, vol.~5, no.~4, pp. 8--36, Dec 2017.

\bibitem{gmbf}
J.~Gambini, M.~Mejail, J.~Jacobo-Berlles, and A.~C. Frery, ``Feature extraction
  in speckled imagery using dynamic {B}-spline deformable contours under the
  {G0} model,'' \emph{Int. J. Remote Sens.}, vol.~27, no.~22, pp. 5037--5059,
  2006.

\bibitem{fbgm}
A.~C. Frery, J.~Jacobo-Berlles, J.~Gambini, and M.~Mejail, ``Polarimetric {SAR}
  image segmentation with {B-Splines} and a new statistical model,''
  \emph{Multidimension. Syst. Signal Process.}, vol.~21, pp. 319--342, 2010.

\bibitem{nhfc}
A.~Nascimento, M.~Horta, A.~Frery, and R.~Cintra, ``Comparing edge detection
  methods based on stochastic entropies and distances for {P}ol{SAR} imagery,''
  \emph{IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens.}, vol.~7, no.~2,
  pp. 648--663, 2014.

\bibitem{mit}
H.~Mitchell, \emph{Image Fusion: Theories, Techniques and Applications}.\hskip
  1em plus 0.5em minus 0.4em\relax Springer Berlin Heidelberg, 2010.

\bibitem{bmf_2019}
A.~A. {de Borba}, M.~{Marengoni}, and A.~C. {Frery}, ``Fusion of evidences for
  edge detection in {PolSAR} images,'' in \emph{2019 IEEE Recent Advances in
  Geoscience and Remote Sensing: Technologies, Standards and Applications
  (TENGARSS)}, Oct 2019, pp. 80--85.

\bibitem{gmbf_sc}
J.~Gambini, M.~Mejail, J.~Jacobo{-}Berlles, and A.~C. Frery, ``Accuracy of edge
  detection methods with local information in speckled imagery,''
  \emph{Statistics and Computing}, vol.~18, no.~1, pp. 15--26, 2008.

\bibitem{xgsh}
Y.~Xiang, S.~Gubian, B.~Suomela, and J.~Hoeng, ``{Generalized Simulated
  Annealing for Global Optimization: The {GenSA} Package},'' \emph{The R
  Journal}, vol.~5, no.~1, pp. 13--28, 2013.

\bibitem{n_r}
V.~Naidu and J.~Raol, ``Pixel-level image fusion using wavelets and principal
  component analysis,'' \emph{Defence Science Journal}, vol.~58, pp. 338--352,
  Mar. 2008.

\bibitem{gs}
S.~Giannarou and T.~Stathaki, ``Optimal edge detection using multiple operators
  for image understanding,'' \emph{EURASIP Journal on Advances in Signal
  Processing}, vol. 2011, no.~1, p.~28, Jul 2011.

\bibitem{jjly}
Q.~{Jiang}, X.~{Jin}, S.~{Lee}, and S.~{Yao}, ``A novel multi-focus image
  fusion method based on stationary wavelet transform and local features of
  fuzzy sets,'' \emph{IEEE Access}, vol.~5, pp. 20\,286--20\,302, 2017.

\bibitem{naidu}
V.~Naidu, ``Image fusion technique using multi-resolution singular value
  decomposition,'' \emph{Defence Science Journal}, vol.~61, no.~5, pp.
  479--484, Sep. 2011.

\bibitem{ht}
A.~Henningsen and O.~Toomet, ``maxlik: A package for maximum likelihood
  estimation in {R},'' \emph{Computational Statistics}, vol.~26, no.~3, pp.
  443--458, 2011.

\end{thebibliography}
\end{document}

